## 流水线阶段

流水线技术是提高 CPU 吞吐量的有效手段。通过将单周期处理器分解成 5 个流水线阶段来构成流水线处理器。5 级流水的 CPU 在每个流水阶段都可以执行 1 条指令，那么同时就有 5 条指令并行，这大大提高了 CPU 的吞吐量。

我们 CPU 为的 5 级流水线阶段为：

| 阶段                  | 简称 | 功能概述                                               |
| :-------------------- | :--- | :----------------------------------------------------- |
| 取指阶段（Fetch）     | F    | 从指令存储器中读取指令                                 |
| 译码阶段（Decode）    | D    | 从寄存器文件中读取源操作数并对指令译码以便得到控制信号 |
| 执行阶段（Execute）   | E    | 使用 ALU 执行计算                                      |
| 存储阶段（Memory）    | M    | 读或写数据存储器                                       |
| 写回阶段（Writeback） | W    | 将结果写回到寄存器文件                                 |

我们流水线寄存器以其提供数据的流水级的简称命名，如 D 级流水线寄存器的前一级为 F 级，而后一级为 D 级。

下面我们对 P5 中涉及的指令进行分析，以此讲解流水线寄存器的工作原理和需要保存哪些数据：

**R 型算术运算指令：add、sub**

Fetch 阶段：从 PC 寄存器取地址，根据地址从 IM 获得指令编码，在下一周期存入 D 级寄存器。

Decode 阶段：从 D 级寄存器取出指令，根据相应寄存器 rs、rt 地址获取其中数据，与 rd 地址一起在下一周期存入 E 级寄存器中。

Execute 阶段：从 E 级寄存器获得上一阶段从 RF 中取得的值，经过 ALU 计算，下一周期将存入 M 级寄存器中，rd 地址继续流水。

Memory 阶段：rd 地址与 ALU 结果继续流水。

Writeback 阶段：W 级寄存器为 RF 提供 rd 地址与 WD，将相应数据写入 rd 中。

**带有立即数的 I 型算数、逻辑运算指令：ori、lui**

这类指令与之前的 R 型算数、逻辑运算指令大致相似，不同之处在于 D 和 E 阶段的处理。

Decode 阶段：将指令低 16 位取出经过 EXT 存入 E 级寄存器。

Execute 阶段：E 级寄存器提供 EXT 的结果，经过多路选择器提供给 ALU 的 B 端。

**内存访问指令：lw**

访存时写入寄存器变为 rt，需要在 ID 级增加一个 MUX，同时，在 M 级需要 ALU 的输出来指定 DM 的地址获得数据，这个数据随着流水线传到 W 阶段写入 RF，因此在 W 阶段需要增设一个 MUX。

Execute 阶段：将 rt 作为目的寄存器存入 ID/EX 寄存器。

Memory 阶段：根据 ALU 计算出的地址仿存，并将数据存入 MEM/WB 寄存器。

Writeback 阶段：通过多选器将数据写入 rt 寄存器。

**内存写入指令：sw**

内存的写入在 M 级需要增加为 DM 提供的写入数据，并且在 W 阶段没有实质性的数据通路，即无需写回到 RF。

Execute 阶段：通过 rs 寄存器的数据与立即数计算地址。

Memory 阶段：将 rt 寄存器的数据写入 ALU 计算出的地址。

**跳转 B 型指令：beq**

在分析跳转指令开始之前，我们首先需要考虑 PC 寄存器，由于指令是顺序执行的，因此我们需要不断为 PC 寄存器加 4。

完善 PC 寄存器的实现后，我们开始正式分析 beq 这个指令，beq 需要在取出 rs、rt 寄存器的值后进行比较，然后决定是否跳转到新的 PC 值，新的 PC 的值可以通过 ID 级有符号扩展后，左移两位，再与 PC + 4 相加得到。

Decode 阶段：比较读取出的 rs 和 rt 寄存器的数据，若相等，则通过多选器将拓展后的立即数作为下一周期的 PC 写入 PC 寄存器。

**延迟槽的实质：在D级进行判断，再进行写入，故执行了beq的下一条指令**

**跳转 J 型指令：jal**

J 型跳转指令同样无条件的可以在 D 级就修改 PC 寄存器的值，但需要在 ID 级增加一个扩展 26 位立即数的部件，同时，jal 需要写入 ra 寄存器，PC + 8 的值需要流水至 W 级写入 RF。

Decode 阶段：通过多选器将拓展后的立即数作为下一周期的 PC 写入。

Execute 阶段：将跳转前的 PC 存入 EX/MEM 寄存器。

Memory 阶段：将跳转前的 PC 存入 MEM/WB 寄存器。

Writeback 阶段：将跳转前的 PC + 8 写入 31 号 ra 寄存器。

**跳转 R 型指令：jr**

R 型跳转指令将 rs 写入 PC 寄存器，可以在 D 级就修改 PC 寄存器，因此只需在 D 级增加一个 MUX。

Decode 阶段：通过多选器将 rs 寄存器的数据作为下一周期的 PC 写入。

![image-20231111172521270](https://pigkiller-011955-1319328397.cos.ap-beijing.myqcloud.com/img/202311111725438.png)

## 流水数据的选择

一般而言，我们需要**流水的数据只有一个衡量标准，就是我们在其后的流水阶段中需不需要这个数据**，比如说 ALU 的计算结果，有的会被写回寄存器文件中，所以我们需要流水这个数据，而 rs 对应的寄存器值，在 M 级和 W 级并没有用到，所以就可以不再流水（仅一般情况）。我们可以这样说，**每个流水线寄存器都保存着一条指令完成后续操作所需要的的全部信息。**

当一个数据被选择成为了流水数据，那么其在 CPU 中就可能存在多个值。比如 E, M, W 级均会有 ALU 的计算结果（三者并不相同），在编程的时候应当使用流水阶段名前缀将其区分开。

# 冒险的种类

在流水线系统中，多条指令同时执行，当一条指令依赖于还没有结束的另一条指令的结果时，将发生冒险（hazard），也被称为“**冲突**”。冒险的类型，主要有**结构冒险（ Structural Hazard ）、控制冒险（ Control Hazard ）和数据冒险（ Data Hazard ）**三种。

## 结构冒险

结构冒险是指**不同指令同时需要使用同一资源**的情况。例如在普林斯顿结构中，指令存储器和数据存储器是同一存储器，在取指阶段和存储阶段都需要使用这个存储器，这时便产生了结构冒险。我们的实验采用哈佛体系结构，将指令存储器和数据存储器分开，因此不存在这种结构冒险。

另一种结构冒险在于寄存器文件需要在 D 级和 W 级同时被使用（读写）时并且读和写的寄存器为同一个寄存器时。

## 控制冒险

控制冒险，是指**分支指令（如 beq ）的判断结果会影响接下来指令的执行流**的情况。在判断结果产生之前，我们无法预测分支是否会发生。然而，此时流水线还会继续取指，让后续指令进入流水线。这时就有可能导致错误的产生，即不该被执行的指令进入到了指令的执行流中。

## 数据冒险

流水线之所以会产生数据冒险，就是因为后面指令需求的数据，正好就是前面指令供给的数据，而后面指令在需要使用数据时，前面供给的数据还没有存入寄存器堆，从而导致后面的指令不能正常地读取到正确的数据。

# 冒险的解决

## 阻塞

这是最为容易的解决方法。冲突的本质是由于指令间存在相关性或依赖相同的部件，导致两条指令无法在相邻的时钟周期内相继执行。也就是说，只要把发生冲突的两条指令之间“分隔开”，就可以有效的解决冒险的问题。

**阻塞**是指当发生数据依赖时，只让前一条指令执行，而后一条指令被阻塞在流水线的某个阶段，并不向下执行，等待前一条指令执行完成（或者执行到没有冲突的时候），再解除后一条的阻塞状态。在我们的 CPU 中，**我们将会发生冒险的指令阻塞在 D 流水级上**。

在 D 级阻塞的时候，像下一流水级传递的指令不应当是 D 级指令，否则 D 级指令还是会向下一流水级传递。所以我们应当插入“指令气泡（bubble）”，也就是 nop 空指令来避免这种情况。实现 CPU 流水级的“空转”。

## 提前分支判断

在 P4 中，我们的分支判断是利用 ALU 实现的，也就对应我们现在的 E 级中实现。在不考虑阻塞的情况下，当我们在 E 级得到分支结果后，若跳转，则此时 F、D 级的指令都需要作废，这无疑是一种低效的方式。

如果我们将分支判断提前到 D 级，那么即使发生跳转，需要作废的指令只有 F 级。其本质是尽早产生结果可以缩短因不确定而带来的开销。

## 延迟槽

在前面我们提到即使将分支判断提到 D 级，发生跳转的时候，F 级指令依然是需要作废的。但是我们如果约定 F 级指令不作废呢？也就是说，不论判断结果如何，我们都将执行分支或跳转指令的下一条指令。这也就是所谓的“**延迟槽**”。那么指令执行的效率就提高了。

再次强调，延迟槽是基本上不需要实现的，也就是说，只要不考虑 F 级指令的作废问题，就是实现了延迟槽。唯一需要变更的是，**对于 jal 指令，应当向 31 号寄存器写入 D_PC + 8 或者 F_PC + 4（当 jal 指令在 D 级时）**。

延迟槽中的指令到底是什么，是由编译器决定的（一个把高级语言翻译成汇编语言的软件），并不需要 CPU 的设计者（也就是我们）操心。编译器保证**延迟槽中的指令不能为分支或跳转指令**。

## 转发

虽然阻塞可以解决全部冒险问题（阻塞的极限情况就是单周期 CPU），但是这无疑会降低 CPU 的并行度，使 CPU 的吞吐量减少。阻塞的本质是说，因为后一条指令需要前一条指令的执行结果，只有让后一条指令等到前一条指令写入寄存器，才可以继续执行。

但是我们考虑数据并非一定要等到写入寄存器堆中才可以被使用，以 add 指令为例，其结果在 E 级时就已经计算完成。那么就没必要再让后面被阻塞的指令多等一个周期，我们现在可以在 M 级就把这个结果传递回去，让 D 级指令解除阻塞状态，这样提高了 CPU 的并行度。直接从后面的流水级的供给者把计算结果发送到前面流水级的需求者来引用，这个过程就叫做**转发**，它可以用于处理**部分的数据冒险**情况。

**$A$模型**

$A$模型描述的是一个很显然的事情，就是需求者和供给者转发的数据必须是同一个寄存器的值。如果需求者需要 5 号寄存器中的值，而供给者只能提供 8 号寄存器中的值，那么显然转发是不能发生的。

我们的$A$指 Address，也就是**寄存器的地址**（编号）。在转发的时候需要检验需求者和供给者的对应的 �*A* 值是否相等，且不为 0。

**$T$模型**

可以看到，转发需要考虑的因素有很多，稍有不慎就会犯下错误。所以我们需要一个**数学模型**来描述转发，即**需求时间-供给时间模型**。

对于某一个指令的某一个数据需求，我们定义需求时间$T_{use}$为：这条指令位于 D 级的时候，再经过多少个时钟周期就必须要使用相应的数据。例如，对于`beq`指令，立刻就要使用数据，所以$T_{use}=0$。对于 add 指令，等待下一个时钟周期它进入 E 级才要使用数据，所以$T_{use}=1$。而对于 sw 指令，在 E 级它需要 GPR[rs] 的数据来计算地址，在 M 级需要 GPR[rt] 来存入值，所以$rs\_T_{use}=1$ ，$rt\_T_{use}$。

我们可以归纳出$T_{use}$的两条性质：

- $T_{use}$是一个定值，每个指令的$T_{use}$是一定的；
- 一个指令可以有两个$T_{use}$值。

对于某个指令的数据产出，我们定义供给时间$T_{new}$为：当前位于**某个流水级**的**某个指令**，它经过多少个时钟周期可以算出结果并且存储到流水级寄存器里。例如，对于 add 指令，当它处于 E 级，此时结果还没有存储到流水级寄存器里，所以此时它的，$T_{new}=1$，而当它处于 M 或者 W 级，此时结果已经写入了流水级寄存器，所以此时$T_{new}=1$。

我们可以归纳出$T_{new}$的两条性质：

- $T_{new}$ 是一个动态值，每个指令处于流水线不同阶段有不同的$T_{new}$值；
- 一个指令在一个时刻至多有一个$T_{new}$值（一个指令至多写一个寄存器）。

 在阐述完所有的数学概念后，我们就可以利用这些概念来描述转发的条件：

- 当$T_{use}>=T_{new}$，说明需要的数据可以及时算出，可以通过**转发**来解决。
- 当$T_{use}<=T_{new}$，说明需要的数据不能及时算出，必须**阻塞**流水线解决。

A模型和T模型结合就形成了 **AT 法**的理论基础。

# 解决冒险的流水线实现

## 译码器的实现

因为整个数据冒险的处理都可以用 AT 法概括描述，这要求我们在译码的时候，不能只译码出指令信息，还需要译码出指令相关的 AT 信息。只有译码出了 AT 信息，才可以帮助我们进行流水线的决策。

当我们采用集中式译码的时候，AT 信息只在 D 级被译码了一次，但是同一个指令的 AT 值在不同的流水线阶段可能会发生变化，所以这就要求我们应当在流水线寄存器中完成流水级间的变化，比如某种实现的$M\_T_{new}=\max(E\_T_{new}-1,0)$。也可以不在流水线寄存器中完成，而是开辟一个新的功能单元完成。

对于分布式译码，因为 AT 信息在每个流水线都被译码，所以就不存在传递变化的问题，但是译码器就必须知道自己所在的流水级，才能给出对应的正确的 AT 值。

## 阻塞的实现

为了方便处理，**课程组要求阻塞是指将指令阻塞在 D 级**。

**当一个指令到达 D 级后，我们需要将它的$T_{use}$值与后面每一级的$T_{new}$进行比较**（当然还有A值的校验），当$T_{use}<T_{new}$时，我们需要阻塞流水线。

阻塞的实现需要改造流水线寄存器和 PC ，我们需要让它们具有以下功能：

- **冻结 PC 的值**；
- 冻结 D 级流水线寄存器的值；
- 将 E 级流水线寄存器清零（这等价于插入了一个 nop 指令）。

此外，还有一个考虑，就是复位信号和阻塞信号的优先级问题。请仔细设计信号的优先级来保证流水线的正确性。

## 内部转发的实现

GPR 是一个特殊的部件，它既可以视为 D 级的一个部件，**也可以视为 W 级之后的流水线寄存器**。基于这一特性，我们将对 GPR 采用**内部转发**机制。也就是说，**当前 GPR 被写入的值会即时反馈到读取端上**。

具体的说，**当读寄存器时的地址与同周期写寄存器的地址相同时，我们将读取的内容改为写寄存器的内容，而不是该地址可以索引到的寄存器文件中的值**。

## 转发的实现

当一个指令到达 D 级后，我们需要将它的$T_{use}$值与后面每一级的$T_{new}$进行比较（当然还有A值的校验），当 $T_{use}>=T_{new}$时，我们需要进行转发。

为了实现转发，我们需要两种多路选择器 MUX，分别对应转发的供给者和需求者。

转发的供给者其实不需要考虑转发的需求者是谁，因为对于一条指令，他能提供的数据至多一种，他如果不是写指令，就不会提供数据，如果他是写指令，也要区分需要写的数据是否产生。如果是写指令，就通过一个 MUX 从流水线寄存器的输出里选择结果，比如 add 就会选择 ALUOut，lw 就会选择 DMOut ，此时衍生了一个问题，就是万一没有怎么办？比如在 EREG 中，就没有 DMOut ，这时就需要单独的设计了。这是第一种MUX，输入是流水线寄存器的输出，输出是当前指令对应的写数据。

**转发的需求者应该是流水级的某个数据，而不是某个模块**。例如在 D 级时，我们需要读出的数据就是 rs 对应的寄存器数据（rsOut）和 rt 对应的寄存器数据（rtOut），然后才是利用这些数据进行各种处理。所以我们转发的目的不应该是仅仅为模块提供正确数据，而应是把 rsOut 和 rtOut 换成正确的，经过转发后的数据 FW_rsOut ，FW_rtOut，这样就是两个 MUX。这是第二种 MUX，输入是各级的第一种 MUX 的输出，输出是当前正确（或者可以容忍的错误）的读数据。

## 控制器的实现

我们解决冒险需要进行 AT 值的比较判断，并需要根据判断的结果产生特定的控制信息。这些功能要求我们丰富我们的控制器，使其可以支持这些功能。

我们的控制器需要产生的信号包括但不限于**冻结信号，刷新信号，供给者选择器信号，需求者选择器信号**等。

## 实例

这里我们以 {add, lw, beq} 这三条指令为例来具体介绍 AT 法如何解决流水线数据冒险。

### Tuse 和 Tnew 的分析

$T_{use}$表示数据到了 D 级之后还需要多少个周期要使用，每个指令的$T_{use}$是固定不变的。

让我们先来分析这些指令的$T_{use}$：

- 对于 add 指令，在 E 级使用 GPR[rs] 和 GPR[rt] 的值，因此$rt\_T_{use}=rs\_T_{use}=1$
- 对于 lw 指令，在 E 级使用 GPR[rs] 的值，因此$rs\_T_{use}=1$
- 对于beq 指令，在 D 级使用 GPR[rs] 和 GPR[rt] 的值，因此$rs\_T_{use}=rt\_T_{use}=0$

$T_{new}$表示数据还有多长时间产生，会随着数据的流水动态的减少。

让我们来分析这些指令在 E 级的$T_{new}$：

- 对于 add 指令，结果在 E 级被计算出来，在 E 级还需要 1 个时钟周期才能将结果放到流水寄存器中，因此 $E\_T_{new}=1$
- 对于 lw 指令，结果在 M 级从 DM 中取出，在 E 级时还需要 2 个时钟周期才能将结果放到流水寄存器中，因此 $E\_T_{new}=2$
- 对于 beq 指令，不产生新数据，我们认为$E\_T_{new}=0$

当数据从一个流水级到下一个流水级时，在流水寄存器中需要更新$T_{new}$，递推公式为$T'_{new}=\max(T_{new}-1,0)$，**注意 不$T_{new}$会小于零**，据此我们可列出这些指令在不同流水级的$T_{new}$：

| 指令 | $E\_T_{new}$ | $M\_T_{new}$ | $W\_T_{new}$ |
| :--: | :----------: | :--------: | :----------: |
| add  |      1       |     0      |      0       |
|  lw  |      2       |     1      |      0       |
| beq  |      0       |     0      |      0       |

### 转发和暂停的分析

我们知道，当$T_{use}>=T_{new}$时，可以通过转发解决；当$T\_{use}<T_{new}$必须阻塞流水线。

根据上述的$T_{use}$和$T_{new}$的值，我们做出策略矩阵，其中 F 表示转发，S 表示暂停：

![image-20231111175020919](https://pigkiller-011955-1319328397.cos.ap-beijing.myqcloud.com/img/202311111750994.png)

根据上表，可以看出只有四种情况需要阻塞：

- $E\_T_{new}=2,=T_{use}=0$
- $E\_T_{new}=1,=T_{use}=0$
- $M\_T_{new}=1,=T_{use}=0$
- $E\_T_{new}=2,=T_{use}=1$

除了这四种，剩下的情况就是需要转发的了。在转发中，我们需要特别注意转发的优先级问题和 rt 域有效性问题。

转发优先级问题是当多个数据可以转发，选择哪个数据的问题，如下面这个指令序列：

```perl
lw      $1, 0x10
add     $1, $2, $3
beq     $1, $0
```

![image-20231111175551153](https://pigkiller-011955-1319328397.cos.ap-beijing.myqcloud.com/img/202311111755299.png)

从上图可以看出，当 beq 在 D 级时，CMP 模块所需的 $1 寄存器的值在 add 指令中产生了一个新值（即上图中红线），并且这个新值无法通过转发的方式转发到 D 级，因此，我们此时不得不先暂停一个周期。

![image-20231111175603226](https://pigkiller-011955-1319328397.cos.ap-beijing.myqcloud.com/img/202311111756431.png)

暂停一个周期后，我们发现 lw 和 add 两条指令产生了 $1 寄存器的两个新值（即上图中的两条红线）且两个数据都可以转发到 D 级。那么此时我们应当选用哪一级的转发数据转发到 D 级呢？但显然，我们应该用 M 级，也就是 add 产生的数据，因为他会覆盖掉前面 lw 产生的数据。也就是说，我们要选择流水线中靠前的“新鲜”的数据进行转发。

rt 域有效性问题是指有些指令的 rt 域不是用来表示读寄存器编号的，比如 j 指令没有 rt 域、ori 指令的 rt 域表示写入寄存器的编号，那么我们是否需要对这些指令进行特判呢？答案是不需要。对于 rt 域无效的指令，即使我们转发了相应的数据，也不会影响流水线的正确性，因此无需特判。

### 具体的实现

可能有些同学看了上面的讲述，在设计上仍有些疑惑，这里我们给出一个具体实现的例子，供有需要的同学参考。同学们完全可以有不一样的实现方式，满足提交要求即可，我们也鼓励大家给出更优秀的实现方式。

为解决流水线数据冒险，我们可以单独设计一个冒险控制模块，输入用于判断暂停和转发的 A 和 T 信号，输出暂停和转发的控制信号，下面让我们一起来分析该模块内部的逻辑。

对于暂停，我们可以根据$T_{use}$和$T_{new}$值的不同组合构造出 4 种暂停信号。当然除了上述 T 的条件，暂停时还需要满足 A 的条件（即读寄存器和写寄存器编号相同且不为 0、写寄存器信号有效)。以 rs 寄存器为例，我们可以写出暂停条件：

```verilog
// 这里的 Stall_RS0_E2 对应 rs_Tuse = 0, E_Tnew = 2 的情况
// Tuse_RS0 表示 rs_Tuse == 0
// A1 表示指令中 [25:21] 域，A3 表示指令中 [15:11] 域
//很关键，输出供给相同则进行“无脑转发”
Stall_RS0_E2 = Tuse_RS0 & (Tnew_E == 2'b10) & (A1_D == A3_E) & (A1_D != 5'd0) & RegWrite_E;
Stall_RS0_E1 = ......
......

Stall_RS = Stall_RS0_E2 | Stall_RS0_E1 | ......
```

rt 寄存器同理，最后总的暂停信号把两个寄存器分别的暂停信号或起来即可。

简单起见，我们约定暂停只发生在 D 级，因此当暂停信号有效时，我们需要保持 D 级流水寄存器，清空 E 级流水寄存器。

对于转发，我们首先要在需要转发的点位放一个多路选择器，可以让 0 路对应原始数据，剩下的路按照数据优先级从低到高排列，然后利用一个转发控制信号选择正确的值。转发控制信号在冒险控制模块内生成，具体的判断条件是：读寄存器和写寄存器编号相同且不为 0、写寄存器信号有效（A 条件）以及转发流水级$T_{new}$（T 条件，表示此时数据已经准备好了）。以 E 级 ALU 中对应 GRF[rs] 的输入端为例：

```verilog
// AR_M 表示 M 级流水寄存器中储存着的 ALU 结果，即 M 级转发数据
// WD_W 表示 W 级流水寄存器中将要写回到寄存器堆的值，即 W 级转发数据
MF_V1 = (MF_V1_SEL == 2'b10) ? AR_M :
        (MF_V1_SEL == 2'b01) ? WD_W : V1_E;

MF_V1_SEL = (A1_E == A3_M && A1_E != 5'd0 && Tnew_M == 2'b00 && RegWrite_M == 1'b1) ? 2'b10 :
            (A1_E == A3_W && A1_E != 5'd0 && Tnew_W == 2'b00 && RegWrite_W == 1'b1) ? 2'b01 : 2'b00;
```

至此，我们就基本解决了流水线数据冒险的核心问题，剩下的部分就留给聪明的你了，相信你一定能够顺利解决！





在这一阶段，我们找到D级生成的`Tuse_rs`和`Tuse_rt`和在E,M,W级寄存器中流水的`Tnew_D`，`Tnew_M`，`Tnew_W`，如下表所示

- **Tuse表**

  | 指令类型 | `Tuse_rs` | `Tuse_rt` |
  | :------- | :-------- | :-------- |
  | calc_R   | 1         | 1         |
  | calc_I   | 1         | X         |
  | shift    | X         | 1         |
  | shiftv   | 1         | 1         |
  | load     | 1         | X         |
  | store    | 1         | 2         |
  | branch   | 0         | 0         |
  | jump     | X         | X         |
  | jr       | 0         | X         |

- **Tnew表**

  | 指令类型 | `Tnew_D` | `Tnew_E` | `Tnew_M` | `Tnew_W` |
  | :------- | :------- | :------- | :------- | :------- |
  | calc_R   | 2        | 1        | 0        | 0        |
  | calc_I   | 2        | 1        | 0        | 0        |
  | shift    | 2        | 1        | 0        | 0        |
  | shiftv   | 2        | 1        | 0        | 0        |
  | load     | 3        | 2        | 1        | 0        |
  | store    | X        | X        | X        | X        |
  | branch   | X        | X        | X        | X        |
  | jal      | 0        | 0        | 0        | 0        |
  | jr       | X        | X        | X        | X        |
  | lui      | 1        | 0        | 0        | 0        |

然后我们Tnew和Tuse传入HCU（冒险控制器中），然后进行stall信号的计算。如果Tnew > Tuse，HCU中的stall信号值为1，此时执行以下操作——

- 冻结PC寄存器（IFU_en = ~stall = 0）
- 冻结D级寄存器（D_en = ~stall = 0）
- 清空E级寄存器（E_clr = stall = 1）